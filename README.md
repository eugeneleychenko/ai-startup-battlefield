# AI Battle Arena ğŸ¤–âš”ï¸

A real-time AI model competition platform where multiple AI models generate startup pitches simultaneously, with an AI judge determining the winner.

## ğŸš€ Features

- **Multi-Model Competition**: Groq (Llama 3.3), OpenAI (GPT-4o), and Anthropic (Claude Sonnet 4) generate pitches in parallel
- **AI Judge**: Anthropic Claude Opus 4.1 evaluates and scores all pitches
- **Real-time Streaming**: Watch pitches generate live with streaming responses
- **Modern UI**: Built with Next.js, Tailwind CSS, and shadcn/ui components
- **Error Handling**: Robust fallback strategies and retry mechanisms
- **Responsive Design**: Works seamlessly on desktop and mobile

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 14 with App Router
- **AI Integration**: Vercel AI SDK
- **Models**: 
  - Groq (Llama 3.3 70B Versatile)
  - OpenAI (GPT-4o)
  - Anthropic (Claude Sonnet 4 & Opus 4.1)
- **Styling**: Tailwind CSS + shadcn/ui
- **Language**: TypeScript

## ğŸƒâ€â™‚ï¸ Quick Start

### Prerequisites

- Node.js 18+
- npm/pnpm/yarn
- API keys for Groq, OpenAI, and Anthropic

### Installation

1. Clone the repository:
```bash
git clone https://github.com/eugeneleychenko/ai-startup-battlefield.git
cd ai-startup-battlefield
```

2. Install dependencies:
```bash
npm install
# or
pnpm install
```

3. Set up environment variables:
```bash
cp .env.example .env.local
```

4. Add your API keys to `.env.local`:
```env
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GROQ_API_KEY=your_groq_key
```

5. Run the development server:
```bash
npm run dev
```

6. Open [http://localhost:3000](http://localhost:3000) in your browser

## ğŸ® How to Use

1. **Enter Your Concept**: Type in your startup idea (e.g., "Uber for dogs")
2. **Choose Target Group**: Select your target audience (e.g., "busy pet owners")
3. **Spin the Wheel**: Click the central button to start the battle
4. **Watch the Magic**: See three AI models generate unique pitches simultaneously
5. **Judge's Verdict**: Claude Opus 4.1 evaluates all pitches and declares a winner

## ğŸ“ Project Structure

```
ai-battle-arena/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ pitch/           # Model-specific pitch generation
â”‚   â”‚   â”‚   â”œâ”€â”€ groq/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”‚   â””â”€â”€ anthropic/
â”‚   â”‚   â””â”€â”€ judge/           # AI judge evaluation
â”‚   â”œâ”€â”€ globals.css
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â””â”€â”€ page.tsx
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                  # shadcn/ui components
â”‚   â”œâ”€â”€ battle-arena.tsx     # Main competition interface
â”‚   â”œâ”€â”€ judge-verdict.tsx    # Results display
â”‚   â””â”€â”€ spinning-wheels.tsx  # Loading animations
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api-client.ts        # API utilities
â”‚   â”œâ”€â”€ prompt-templates.ts  # AI prompts
â”‚   â””â”€â”€ types.ts             # TypeScript definitions
â””â”€â”€ docs/
    â”œâ”€â”€ tasklist.md          # Implementation checklist
    â””â”€â”€ tech_spec.md         # Technical specification
```

## ğŸ§ª API Endpoints

- `POST /api/pitch/groq` - Generate pitch using Llama 3.3
- `POST /api/pitch/openai` - Generate pitch using GPT-4o  
- `POST /api/pitch/anthropic` - Generate pitch using Claude Sonnet 4
- `POST /api/judge` - Evaluate pitches using Claude Opus 4.1
- `GET /api/health` - Health check endpoint

## ğŸš€ Deployment

### Vercel (Recommended)

1. Connect your GitHub repository to Vercel
2. Add environment variables in Vercel dashboard
3. Deploy automatically on push to main

### Other Platforms

The app can be deployed on any platform supporting Next.js:
- Netlify
- Railway
- DigitalOcean App Platform
- AWS Amplify

## ğŸ”§ Development

### Testing API Routes

Use the included test script:
```bash
node scripts/test-api.js
```

### Error Handling

The application includes comprehensive error handling:
- Connection timeouts (30s per model)
- Retry mechanisms for failed requests
- Graceful degradation (continue with successful models)
- User-friendly error messages

### Performance

- Streaming responses for real-time feedback
- Parallel API calls for maximum speed
- Request debouncing to prevent spam
- Optimized bundle size with dynamic imports

## ğŸ“ License

MIT License - feel free to use this project for learning and experimentation!

## ğŸ¤ Contributing

Contributions welcome! Please read the technical specification in `tech_spec.md` for implementation details.

## ğŸ“ Support

- Check `tasklist.md` for implementation status
- Review `ERROR_HANDLING_SUMMARY.md` for troubleshooting
- Open an issue for bugs or feature requests

---

Built with â¤ï¸ and powered by the latest AI models
